{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook screens that it can perform *train* -> *register model* -> *batch transform* -> *delete model*. It is designed to run in one go without a kernel restart, hence submits only short training and batch-transform jobs each of which runs for 3+ minutes.\n",
    "\n",
    "Steps:\n",
    "- **Pre-requisite**:\n",
    "  * Install `requirements.txt` to conda environment `mxnet_p36`.\n",
    "  * Make sure to choose kernel `conda_mxnet_p36`.\n",
    "- **Action**: click *Kernel* -> *Restart Kernel and Run All Cells...* \n",
    "- **Expected outcome**: no exception seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Before you run the next cell, please open `smconfig.py` and review the mandatory SageMaker `kwargs` then disable the `NotImplementedException` in the last line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import sagemaker as sm\n",
    "from sagemaker import KMeans, KMeansModel\n",
    "\n",
    "import smconfig\n",
    "from smallmatter.pathlib import Path2\n",
    "from smallmatter.sm import get_model_tgz\n",
    "\n",
    "\n",
    "# Configuration of this screening test.\n",
    "sess = sm.Session()\n",
    "sm_kwargs = smconfig.SmKwargs(sm.get_execution_role())\n",
    "s3_input_path = f'{smconfig.s3_bucket}/screening/kmeans-input'\n",
    "s3_sagemaker_path = f'{smconfig.s3_bucket}/screening/sagemaker'\n",
    "\n",
    "# Enforce blocking API to validate permissions to Describe{Training,Transform}Job.\n",
    "block_notebook_while_training = True\n",
    "\n",
    "# Propagate to env vars of the whole notebook, for usage by ! or %%.\n",
    "%set_env BUCKET=$smconfig.s3_bucket\n",
    "%set_env S3_INPUT_PATH=$s3_input_path\n",
    "%set_env S3_SAGEMAKER_PATH=$s3_sagemaker_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KMeans(\n",
    "    k=2,\n",
    "    epochs=5,\n",
    "\n",
    "    # record_set() needs trailing '/'. Otherwise, instead of s3://bucket/sagemaker/kmeans-input/KMeans-xxxx,\n",
    "    # we'll get s3://bucket/sagemaker/kmeans-inputKMeans-xxxx.\n",
    "    data_location=s3_input_path + '/',\n",
    "\n",
    "    output_path=s3_sagemaker_path,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    sagemaker_session=sess,\n",
    "    **sm_kwargs.train,\n",
    ")\n",
    "\n",
    "# Generate synthetic input data as protobuf files on S3.\n",
    "# NOTE: SageMaker K-Means algo REQUIRES float32.\n",
    "train_input = estimator.record_set(\n",
    "    np.random.rand(100, 8).astype('float32')\n",
    ")\n",
    "\n",
    "# Submit a training job.\n",
    "estimator.fit(train_input, wait=block_notebook_while_training)\n",
    "\n",
    "# Track the jobname for subsequent CloudWatch CLI operations.\n",
    "train_job_name = estimator.latest_training_job.name\n",
    "%set_env TRAIN_JOB_NAME=$estimator.latest_training_job.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve CloudWatch log events\n",
    "\n",
    "You can retrieve the training logs using `awscli` after this notebook is unblocked. This will be a good test to verify that this notebook's role has sufficient permissions to read CloudWatch logs.\n",
    "\n",
    "Assuming the job name is stored in an environment variable `TRAIN_JOB_NAME`, run these CLI commands:\n",
    "\n",
    "```bash\n",
    "# Find out the log-stream name; should look like TRAIN_JOB_NAME/xxx.\n",
    "aws logs describe-log-streams \\\n",
    "    --log-group-name /aws/sagemaker/TrainingJobs \\\n",
    "    --log-stream-name-prefix $TRAIN_JOB_NAME \\\n",
    "    | jq -r '.logStreams[].logStreamName'\n",
    "\n",
    "\n",
    "# Get the log events\n",
    "aws logs get-log-events \\\n",
    "    --log-group-name /aws/sagemaker/TrainingJobs \\\n",
    "    --log-stream-name <LOG_STREAM_NAME>\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Inspect model artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model artifact `s3://bucket/sagemaker/train_job_name/output/model.tar.gz` contains the cluster centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract model artifact to /tmp\n",
    "model_artifact = str(get_model_tgz(train_job_name, sess.sagemaker_client))\n",
    "%env MODEL_ARTIFACT=$model_artifact\n",
    "!aws s3 cp $MODEL_ARTIFACT - | tar -C /tmp -xzf -\n",
    "\n",
    "# Load & inspect\n",
    "kmeans_model_params = mx.ndarray.load('/tmp/model_algo-1')\n",
    "cluster_centroids = pd.DataFrame(kmeans_model_params[0].asnumpy())\n",
    "\n",
    "print(\n",
    "    f'type(kmeans_model_params) = {type(kmeans_model_params)}',\n",
    "    f'len(kmeans_model_params) = {len(kmeans_model_params)}',\n",
    "    sep='\\n'\n",
    ")\n",
    "for i,o in enumerate(kmeans_model_params):\n",
    "    print(f'type(kmeans_modle_params[{i}]) = {type(o)}')\n",
    "    try:\n",
    "        print('  => shape:', o.shape, end='\\n\\n')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "cluster_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Transform\n",
    "\n",
    "After training job finishes, we'll assign cluster id to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register model\n",
    "\n",
    "NOTE: if model name already registered, the old registered model will be untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeansModel(\n",
    "    model_data=str(model_artifact),\n",
    "    sagemaker_session=sess,\n",
    "    name='kmeans-screening-1234',\n",
    "    **sm_kwargs.model,\n",
    ")\n",
    "\n",
    "# Create model\n",
    "model._create_sagemaker_model(instance_type='ml.m5.large', tags=sm_kwargs.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Batch-Transform job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_input_src = Path2(train_input.s3_data).parent\n",
    "bt_input_dir = s3_sagemaker_path + '/bt/input'\n",
    "bt_output_dir = s3_sagemaker_path + '/bt/output'\n",
    "# Propagate to env vars but just for this cell.\n",
    "%env BT_INPUT_SRC=$bt_input_src\n",
    "%env BT_INPUT_DIR=$bt_input_dir\n",
    "%env BT_OUTPUT_DIR=$bt_output_dir\n",
    "\n",
    "# The S3 input path to batch transform must contain only protobuf file, so we\n",
    "# simply copy all-but-manifest from the input record set (autogenerated prior\n",
    "# training) to a new area.\n",
    "!aws s3 sync \\\n",
    "    $BT_INPUT_SRC/ \\\n",
    "    $BT_INPUT_DIR/ \\\n",
    "    --exclude .amazon.manifest \\\n",
    "    --storage-class ONEZONE_IA\n",
    "!aws s3 ls $BT_INPUT_DIR/\n",
    "\n",
    "bt = model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    strategy='MultiRecord',\n",
    "    output_path=bt_output_dir + '/',  # Input S3 dir for batch transform must ends with '/'\n",
    "\n",
    "    # https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-inference.html#cm-batch\n",
    "    accept='application/jsonlines',\n",
    "    assemble_with='Line',\n",
    "\n",
    "    **sm_kwargs.bt,\n",
    ")\n",
    "\n",
    "bt.transform(\n",
    "    data=bt_input_dir + '/',   # Output S3 dir for batch transform must ends with '/'\n",
    "    data_type='S3Prefix',\n",
    "    wait=block_notebook_while_training,\n",
    "    logs=True,\n",
    "\n",
    "    # https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-inference#cm-batch\n",
    "    content_type='application/x-recordio-protobuf',\n",
    "    split_type='RecordIO'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect sample output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $BT_OUTPUT_DIR/\n",
    "!aws s3 cp $BT_OUTPUT_DIR/matrix_0.pbr.out - | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De-register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
